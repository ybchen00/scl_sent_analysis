{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom nltk import word_tokenize\nfrom tqdm.notebook import tqdm\n\n#Avoid warning messages\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#plotly libraries\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import model_selection\nfrom textblob import TextBlob\nimport emoji  # https://pypi.org/project/emoji/\nimport re\nimport fasttext","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def readData(path):\n    df=pd.read_csv(path)\n    df.drop('review_id', axis=1, inplace=True)\n    return df\n\ndef lowerCase(df):\n    df['review']=df['review'].str.lower()\n    return df\n\ndef rearrange(df):\n    df['rating'] = df['rating'].replace(to_replace=1, value=\"__label__1\")\n    df['rating'] = df['rating'].replace(to_replace=2, value=\"__label__2\")\n    df['rating'] = df['rating'].replace(to_replace=3, value=\"__label__3\")\n    df['rating'] = df['rating'].replace(to_replace=4, value=\"__label__4\")\n    df['rating'] = df['rating'].replace(to_replace=5, value=\"__label__5\")\n    cols = df.columns.tolist()\n    cols = cols[-1:]+cols[:-1]\n    df=df[cols]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def emoji_process(df):\n    \n    have_emoji_idx = []\n    \n    for idx, review in enumerate(df['review']):\n        if any(char in emoji.UNICODE_EMOJI for char in review):\n            have_emoji_idx.append(idx)\n            \n    def emoji_cleaning(text):\n    \n        # Change emoji to text\n        text = emoji.demojize(text).replace(\":\", \" \")\n\n        # Delete repeated emoji\n        tokenizer = text.split()\n        repeated_list = []\n\n        for word in tokenizer:\n            if word not in repeated_list:\n                repeated_list.append(word)\n\n        text = ' '.join(text for text in repeated_list)\n        text = text.replace(\"_\", \" \").replace(\"-\", \" \")\n        \n        return text\n\n    # emoji_cleaning\n    df.loc[have_emoji_idx, 'review'] = df.loc[have_emoji_idx, 'review'].apply(emoji_cleaning)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def review_clean(df):\n\n    def review_cleaning(text):\n\n        # change emoticon to text\n        text = re.sub(r':\\(', 'dislike', text)\n        text = re.sub(r': \\(\\(', 'dislike', text)\n        text = re.sub(r':, \\(', 'dislike', text)\n        text = re.sub(r':\\)', 'smile', text)\n        text = re.sub(r';\\)', 'smile', text)\n        text = re.sub(r':\\)\\)\\)', 'smile', text)\n        text = re.sub(r':\\)\\)\\)\\)\\)\\)', 'smile', text)\n        text = re.sub(r'=\\)\\)\\)\\)', 'smile', text)\n\n        # delete punctuation\n        text = re.sub('[^a-z0-9 ]', ' ', text)\n\n        tokenizer = text.split()\n\n        return ' '.join([text for text in tokenizer])\n    df[\"review\"]=df[\"review\"].apply(review_cleaning)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainFilePath=\"/kaggle/input/student-shopee-code-league-sentiment-analysis/train.csv\"\ntestFilePath=\"/kaggle/input/student-shopee-code-league-sentiment-analysis/test.csv\"\n#modelPath=\"/kaggle/input/student-shopee-code-league-sentiment-analysis\"\ntrain=readData(trainFilePath)\ntest=readData(testFilePath)\ntrain=lowerCase(train)\ntest=lowerCase(test)\n#train=emoji_process(train)\ntrain=review_clean(train)\ntrain=rearrange(train)\n#print(len(train.columns.tolist()))\nprint(train.head(30))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_csv(r'/kaggle/working/trainK2.txt', header=None, index=None, sep=' ', mode='a')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fasttext\n\nhyper_params = { \n    \"lr\": 0.35,         # Learning rate\n    \"epoch\": 100,       # Number of training epochs to train for\n    \"wordNgrams\": 3,    # Number of word n-grams to consider during training\n    \"dim\": 155,         # Size of word vectors\n    \"ws\": 5,            # Size of the context window for CBOW or skip-gram\n    \"minn\": 2,          # Min length of char ngram\n    \"maxn\": 5,          # Max length of char ngram\n    \"bucket\": 2014846,  # Number of buckets\n}\n\ndef trainer(filepath: str, hyper_params: dict):\n    \n    model = fasttext.train_supervised(input=filepath, **hyper_params)\n    print(\"FastText model trained with hyperparameters: \\n {}\".format(hyper_params))\n    return model\n    # Save models to model directory for fasttext\n\n\n\nmodel=trainer(\"/kaggle/working/trainK2.txt\",hyper_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scoreFT(text: str) -> int:\n        # Predict just the top label (hence 1 index below)\n    labels, probabilities = model.predict(text, 1)\n    pred = int(labels[0][-1])\n    return pred\n\ndef predictFT(df) -> pd.DataFrame:\n    df['pred'] = df['review'].apply(scoreFT)\n    return df\n\ntrain=predictFT(train)\nprint(train.head(30))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateFT(trainPred, trainOrig):\n    total=len(trainPred)\n    correct=np.sum(np.where(trainOrig['rating']==trainPred['pred'],1,0))\n    return correct/total\ntrainOrig=readData(trainFilePath)\nprint(evaluateFT(train, trainOrig))\nprint(trainOrig.head(100))\nprint(pred_train.head(100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}